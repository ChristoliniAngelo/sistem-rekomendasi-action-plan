{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekomendasi Improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.2.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ----------------------------- ---------- 30.7/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 42.0/42.0 kB 675.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.1/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.4/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.5/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 41.0/269.5 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 122.9/269.5 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 194.6/269.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 235.5/269.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 256.0/269.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.5/269.5 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.12.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Baca data dari file Excel\n",
    "data = pd.read_excel('New.xlsx')\n",
    "\n",
    "# Tokenisasi dan pra-pemrosesan teks\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Pengecekan apakah nilai adalah string\n",
    "        tokens = word_tokenize(text.lower())  # Tokenisasi dan konversi ke huruf kecil\n",
    "        filtered_tokens = [token for token in tokens if token.isalnum() and token not in stop_words]  # Hapus tanda baca dan stop words\n",
    "        return \" \".join(filtered_tokens)\n",
    "    else:\n",
    "        return \"\"  # Mengembalikan string kosong jika nilai bukan string\n",
    "\n",
    "# Pra-pemrosesan data \"Key Notes\"\n",
    "data['Cleaned Key Notes'] = data['Key Notes'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representasi teks menggunakan TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['Cleaned Key Notes'])\n",
    "\n",
    "# Fungsi untuk mendapatkan rekomendasi berdasarkan key notes\n",
    "def get_recommendations(key_notes, tfidf_matrix, data, top_n=5):\n",
    "    # Pra-pemrosesan teks input\n",
    "    cleaned_input = preprocess_text(key_notes)\n",
    "\n",
    "    # Representasi vektor untuk input\n",
    "    input_vector = tfidf_vectorizer.transform([cleaned_input])\n",
    "\n",
    "    # Menghitung cosine similarity antara input dan seluruh data\n",
    "    cosine_similarities = cosine_similarity(input_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Mendapatkan indeks dari top_n similarity scores\n",
    "    top_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # Mendapatkan rekomendasi improve berdasarkan top indices\n",
    "    recommendations = data.loc[top_indices, 'Improve'].values\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekomendasi kegiatan improvement:\n",
      "1. Memanfaatkan floating storage eks kapal Phoenix bekas kapal Phoenix sebagai storage MT Reefer untuk mempercepat layanan pengambilan MT Reefer   \n",
      "2.  Memodifikasi sistim pendingin dengan menambah radiator dan Fan\n",
      "3. KOORDINASI DENGAN TIM PURCHASING UNTUK PENGADAAN CONSUMABLE MATERIAL   \n",
      "4. Evaluasi mingguan aktualisasi TL minggu sebelumnya\n",
      "5. Penambahan extra engine mounting pada 17 unit  trailler sehingga menambah endurance unit dalam pelayanan\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan\n",
    "key_notes = \"Muatan\"\n",
    "recommendations = get_recommendations(key_notes, tfidf_matrix, data)\n",
    "\n",
    "print(\"Rekomendasi kegiatan improvement:\")\n",
    "for idx, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{idx}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Biaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekomendasi kegiatan improvement:\n",
      "1. Penyesuaian tarif ritase tujuan Pelabuhan-Pelabuhan Internasional (berlaku sebaliknya) Rp. 70.000/TEU \n",
      "2. Approach pemilik Satando dengan memberikan garansi LOLO Activity di atas 2.000/bulan\n",
      "3. Koordinasi dengan PBM dalam rencana menambah kapasitas BM di port Marunda. Dengan penambahan muatan dari Padang Bengkulu.\n",
      "4. Koordinasi dengan cabang agar kontainer yang dibongkar sama dengan kontainer yang dimuat\n",
      "5. Evaluasi mingguan aktualisasi TL minggu sebelumnya\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan dengan input\n",
    "key_notes_input = input(\"Masukkan Key Notes: \")\n",
    "recommendations = get_recommendations(key_notes_input, tfidf_matrix, data)\n",
    "\n",
    "print(\"Rekomendasi kegiatan improvement:\")\n",
    "for idx, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{idx}. {rec}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
